{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c13bdb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macbookpro/Desktop/UPSaclay Courses/T4/Information retrieval/Assignment/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "\n",
    "from utils import load_json_data, get_mapping_dict, create_corpus, get_true_and_predicted, mean_average_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea16af0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_citing_train = load_json_data(\"./datasets/Content_JSONs/Citing_2020_Cleaned_Content_12k/Citing_Train_Test/citing_TRAIN.json\")\n",
    "json_citing_test = load_json_data(\"./datasets/Content_JSONs/Citing_2020_Cleaned_Content_12k/Citing_Train_Test/citing_TEST.json\")\n",
    "\n",
    "json_nonciting = load_json_data(\"./datasets/Content_JSONs/Cited_2020_Uncited_2010-2019_Cleaned_Content_22k/CLEANED_CONTENT_DATASET_cited_patents_by_2020_uncited_2010-2019.json\")\n",
    "json_citing_to_cited = load_json_data(\"./datasets/Citation_JSONs/Citation_Train.json\")\n",
    "\n",
    "citing_dataset_df = pd.DataFrame(json_citing_train)\n",
    "\n",
    "nonciting_dataset_df = pd.DataFrame(json_nonciting)\n",
    "mapping_dataset_df = pd.DataFrame(json_citing_to_cited)\n",
    "\n",
    "mapping_dict = get_mapping_dict(mapping_dataset_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bef95dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================\n",
    "# DATASET CLASS FOR PATENT PAIRS\n",
    "# =============================\n",
    "\n",
    "class PatentPairDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom PyTorch Dataset to create patent pairs.\n",
    "    Each sample is a tuple: (citing_text, cited_text, label) tokenized for the chosen model.\n",
    "    \"\"\"\n",
    "    def __init__(self, pairs, tokenizer, max_length=512):\n",
    "        self.pairs = pairs  # List of tuples: (citing_text, cited_text, label)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        citing_text, cited_text, label = self.pairs[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            citing_text,\n",
    "            cited_text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        # Squeeze the batch dimension\n",
    "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "        item['labels'] = torch.tensor(label, dtype=torch.long)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47c5f04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents without title: 0\n",
      "Number of documents without title: 0\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 2. Create Corpora\n",
    "# -----------------------------\n",
    "# Choose a text type such as 'title'; you can change to abstract, claims, etc.\n",
    "citing_corpus = create_corpus(json_citing_train, 'title')\n",
    "nonciting_corpus = create_corpus(json_nonciting, 'title')\n",
    "\n",
    "# Create lookup dictionary for nonciting patents\n",
    "nonciting_lookup = {doc['id']: doc['text'] for doc in nonciting_corpus}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a04b8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a text type such as 'title'; you can change to abstract, claims, etc.\n",
    "citing_corpus = create_corpus(json_citing_train, 'fulltext')\n",
    "nonciting_corpus = create_corpus(json_nonciting, 'fulltext')\n",
    "\n",
    "# Create lookup dictionary for nonciting patents\n",
    "nonciting_lookup = {doc['id']: doc['text'] for doc in nonciting_corpus}\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Build Training Pairs\n",
    "# -----------------------------\n",
    "# Build positive pairs using the mapping dictionary\n",
    "positive_pairs = []\n",
    "for citing_doc in citing_corpus:\n",
    "    citing_id = citing_doc['id']\n",
    "    if citing_id in mapping_dict:\n",
    "        cited_ids = mapping_dict[citing_id]\n",
    "        for cited_id in cited_ids:\n",
    "            if cited_id in nonciting_lookup:\n",
    "                positive_pairs.append((citing_doc['text'], nonciting_lookup[cited_id], 1))\n",
    "\n",
    "# Construct negative pairs by sampling a non-cited patent\n",
    "negative_pairs = []\n",
    "all_nonciting_ids = list(nonciting_lookup.keys())\n",
    "for citing_doc in citing_corpus:\n",
    "    citing_id = citing_doc['id']\n",
    "    true_cited_ids = mapping_dict.get(citing_id, [])\n",
    "    if true_cited_ids:\n",
    "        possible_negatives = list(set(all_nonciting_ids) - set(true_cited_ids))\n",
    "        if possible_negatives:\n",
    "            neg_id = random.choice(possible_negatives)\n",
    "            negative_pairs.append((citing_doc['text'], nonciting_lookup[neg_id], 0))\n",
    "\n",
    "# Combine positive and negative pairs and shuffle\n",
    "all_pairs = positive_pairs + negative_pairs\n",
    "random.shuffle(all_pairs)\n",
    "print(\"Total training pairs:\", len(all_pairs))\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Initialize Tokenizer and Model\n",
    "# -----------------------------\n",
    "# Using the domain-specific model anferico/bert-for-patents\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"anferico/bert-for-patents\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"anferico/bert-for-patents\", num_labels=2)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Create Dataset and Trainer\n",
    "# -----------------------------\n",
    "dataset = PatentPairDataset(all_pairs, tokenizer, max_length=256)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    save_total_limit=1,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Train the Model\n",
    "# -----------------------------\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
